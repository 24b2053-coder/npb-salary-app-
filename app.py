import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# XGBoost/LightGBMã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰
try:
    from xgboost import XGBRegressor
    HAS_XGB = True
except ImportError:
    HAS_XGB = False
    
try:
    from lightgbm import LGBMRegressor
    HAS_LGBM = True
except ImportError:
    HAS_LGBM = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="NPBé¸æ‰‹å¹´ä¿¸äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="âš¾",
    layout="centered",
)

st.markdown("""
<style>

/* ====== ã‚µã‚¤ãƒ‰ãƒãƒ¼å›ºå®š ====== */
[data-testid="stSidebar"] {
    position: fixed !important;
    top: 0;
    left: 0;
    width: 280px !important;
    height: 100vh !important;
    background-color: #ffe4e9 !important;
    border-right: 1px solid #e0e0e0;
    padding: 0 !important;
    margin: 0 !important;
    z-index: 1000000;
    overflow: hidden;
    border-radius: 0px 30px 30px 0;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ */
[data-testid="stSidebarUserContent"] {
    padding-top: 3rem !important;
    margin-top: 0 !important;
}

/* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ */
[data-testid="stSidebarContent"] {
    overflow-y: auto !important;
    height: 100vh !important;
    padding: 0 1rem 1rem 1rem !important;
    margin: 0 !important;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®æœ€åˆã®è¦ç´ ã®ä¸Šä½™ç™½ã‚’å‰Šé™¤ */
[data-testid="stSidebarContent"] > div:first-child {
    margin-top: 0 !important;
    padding-top: 0 !important;
}

/* ã™ã¹ã¦ã®VerticalBlock */
[data-testid="stSidebar"] [data-testid="stVerticalBlock"] {
    gap: 0.5rem !important;
    padding-top: 0 !important;
    margin-top: 0 !important;
}

/* ã™ã¹ã¦ã®element-container */
[data-testid="stSidebar"] .element-container {
    margin-top: 0 !important;
}

[data-testid="stSidebar"] .element-container:first-child {
    margin-top: 0 !important;
    padding-top: 0 !important;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®ã‚«ãƒ¼ã‚½ãƒ«ã‚’æ¨™æº–åŒ– */
[data-testid="stSidebar"] * {
    cursor: default !important;
}

/* ãƒœã‚¿ãƒ³ã‚„ãƒªãƒ³ã‚¯ãªã©ã€ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªè¦ç´ ã®ã¿ãƒã‚¤ãƒ³ã‚¿ãƒ¼ã‚«ãƒ¼ã‚½ãƒ« */
[data-testid="stSidebar"] button,
[data-testid="stSidebar"] a,
[data-testid="stSidebar"] input[type="radio"],
[data-testid="stSidebar"] label[data-baseweb="radio"] {
    cursor: pointer !important;
}

/* ====== ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ====== */
.main {
    margin-left: 280px !important;
}

/* ãƒ¡ã‚¤ãƒ³ã®æœ€å¤§å¹…ã‚’å›ºå®šï¼ˆæºã‚Œé˜²æ­¢ï¼‰ */
.block-container {
    max-width: 1400px !important;
    padding-top: 2rem !important;
}

/* ====== è¡¨ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã®æºã‚Œå¯¾ç­– ====== */
.stDataFrame, .stTable {
    max-width: 100% !important;
}

table {
    table-layout: fixed !important;
    width: 100% !important;
}

thead tr th {
    background-color: #f8f8f8 !important;
}

/* ====== è¦‹å‡ºã—ã®ç¸¦ç·šï¼ˆã‚«ãƒ¼ã‚½ãƒ«ï¼‰ã‚’éè¡¨ç¤º ====== */
h1::before, h2::before, h3::before, h4::before, h5::before, h6::before {
    content: none !important;
    display: none !important;
}

/* Markdownã®è¦‹å‡ºã—ã‚‚å¯¾è±¡ */
.element-container h1::before,
.element-container h2::before,
.element-container h3::before,
.element-container h4::before {
    display: none !important;
}

/* ====== è¦‹å‡ºã—ã®ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯ã‚’å®Œå…¨ã«éè¡¨ç¤º ====== */
h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {
    display: none !important;
    pointer-events: none !important;
}

/* Streamlitã®è¦‹å‡ºã—ã‚¢ãƒ³ã‚«ãƒ¼ */
[data-testid="stHeaderActionElements"] {
    display: none !important;
}

/* è¦‹å‡ºã—ã®ãƒ›ãƒãƒ¼æ™‚ã®ãƒªãƒ³ã‚¯è¡¨ç¤ºã‚‚æ¶ˆã™ */
h1:hover a, h2:hover a, h3:hover a, h4:hover a, h5:hover a, h6:hover a {
    display: none !important;
}

/* ====== ã‚¹ãƒãƒ›å¯¾å¿œ ====== */
@media (max-width: 900px) {
    [data-testid="stSidebar"] {
        position: relative !important;
        width: 100% !important;
        height: auto !important;
        border-right: none !important;
    }
    .main {
        margin-left: 0 !important;
    }
    .block-container {
        max-width: 100% !important;
        padding: 1rem !important;
    }
}

</style>
""", unsafe_allow_html=True)

# CSSã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç„¡åŠ¹åŒ–
st.markdown("""
<style>
    /* ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®éœ‡ãˆã‚’é˜²æ­¢ */
    [data-testid="stDataFrame"] {
        animation: none !important;
        transition: none !important;
    }
    
    /* ãƒ†ãƒ¼ãƒ–ãƒ«å…¨ä½“ã®éœ‡ãˆã‚’é˜²æ­¢ */
    .stDataFrame {
        animation: none !important;
        transition: none !important;
    }
    
    /* å…¨ä½“çš„ãªã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æŠ‘åˆ¶ */
    * {
        animation-duration: 0s !important;
        animation-delay: 0s !important;
        transition-duration: 0s !important;
    }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>

/* ====== ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å…¨ä½“ ====== */
@media (prefers-color-scheme: dark) {

    /* ãƒ¡ã‚¤ãƒ³èƒŒæ™¯ */
    .main, .block-container {
        background-color: #1e1e1e !important;
        color: #f2f2f2 !important;
    }

    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ */
    [data-testid="stSidebar"] {
        background-color: #2a2a2a !important;
        border-right: 1px solid #444 !important;
    }

    /* ãƒ†ã‚­ã‚¹ãƒˆè‰² */
    [data-testid="stSidebar"] *, .main * {
        color: #f2f2f2 !important;
    }

    /* ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ */
    thead tr th {
        background-color: #333 !important;
        color: #fff !important;
    }

    /* ãƒ†ãƒ¼ãƒ–ãƒ«æœ¬ä½“ */
    tbody tr {
        background-color: #2b2b2b !important;
        color: #fff !important;
    }

    /* ãƒœã‚¿ãƒ³ */
    button[kind="primary"], .stButton button {
        background-color: #444 !important;
        color: #fff !important;
        border-radius: 8px;
        border: 1px solid #666 !important;
    }
    button[kind="primary"]:hover, .stButton button:hover {
        background-color: #555 !important;
    }

    /* å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  */
    input, textarea, select, .stTextInput input {
        background-color: #2b2b2b !important;
        color: #fff !important;
        border: 1px solid #666 !important;
    }

    /* ãƒ—ãƒ­ãƒƒãƒˆå‘¨ã‚Šï¼ˆMatplotlibï¼‰ */
    .stPlotlyChart, .stPyplot {
        background-color: #1e1e1e !important;
    }
}

</style>
""", unsafe_allow_html=True)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
try:
    import japanize_matplotlib
    plt.rcParams["font.family"] = "IPAexGothic"
except ImportError:
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']

# æ¸›é¡åˆ¶é™è¨ˆç®—é–¢æ•°
def calculate_salary_limit(previous_salary):
    """
    NPBã®æ¸›é¡åˆ¶é™ã‚’è¨ˆç®—ã™ã‚‹
    1å„„å††ä»¥ä¸Š: 40%ã¾ã§æ¸›é¡å¯èƒ½ï¼ˆæœ€ä½60%ï¼‰
    1å„„å††æœªæº€: 25%ã¾ã§æ¸›é¡å¯èƒ½ï¼ˆæœ€ä½75%ï¼‰
    """
    if previous_salary >= 100_000_000:  # 1å„„å††ä»¥ä¸Š
        reduction_rate = 0.40
        min_salary = previous_salary * 0.60
    else:  # 1å„„å††æœªæº€
        reduction_rate = 0.25
        min_salary = previous_salary * 0.75
    
    return min_salary, reduction_rate

def check_salary_reduction_limit(predicted_salary, previous_salary):
    """
    äºˆæ¸¬å¹´ä¿¸ãŒæ¸›é¡åˆ¶é™ã«å¼•ã£ã‹ã‹ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    """
    min_salary, reduction_rate = calculate_salary_limit(previous_salary)
    
    if predicted_salary < min_salary:
        return True, min_salary, reduction_rate
    else:
        return False, min_salary, reduction_rate

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("âš¾ NPBé¸æ‰‹å¹´ä¿¸äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹å–„ç‰ˆï¼‰")
st.markdown("---")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å‡¦ç†
@st.cache_data
def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    try:
        salary_df = pd.read_csv('data/salary_2023&2024&2025.csv')
        stats_2023 = pd.read_csv('data/stats_2023.csv')
        stats_2024 = pd.read_csv('data/stats_2024.csv')
        stats_2025 = pd.read_csv('data/stats_2025.csv')
        titles_df = pd.read_csv('data/titles_2023&2024&2025.csv')
        return salary_df, stats_2023, stats_2024, stats_2025, titles_df, True
    except FileNotFoundError:
        return None, None, None, None, None, False

salary_df, stats_2023, stats_2024, stats_2025, titles_df, data_loaded = load_data()

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
if not data_loaded:
    st.sidebar.markdown("**5ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€åº¦ã«é¸æŠã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼š**")
    uploaded_files = st.sidebar.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆ5ã¤å…¨ã¦é¸æŠã—ã¦ãã ã•ã„ï¼‰",
        type=['csv'],
        accept_multiple_files=True
    )
    
    if uploaded_files and len(uploaded_files) == 5:
        file_dict = {}
        for file in uploaded_files:
            if 'salary' in file.name or 'å¹´ä¿¸' in file.name:
                file_dict['salary'] = file
            elif 'titles' in file.name or 'ã‚¿ã‚¤ãƒˆãƒ«' in file.name:
                file_dict['titles'] = file
            elif '2023' in file.name:
                file_dict['stats_2023'] = file
            elif '2024' in file.name:
                file_dict['stats_2024'] = file
            elif '2025' in file.name:
                file_dict['stats_2025'] = file
        
        if len(file_dict) == 5:
            salary_df = pd.read_csv(file_dict['salary'])
            stats_2023 = pd.read_csv(file_dict['stats_2023'])
            stats_2024 = pd.read_csv(file_dict['stats_2024'])
            stats_2025 = pd.read_csv(file_dict['stats_2025'])
            titles_df = pd.read_csv(file_dict['titles'])
            data_loaded = True
        else:
            st.sidebar.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«åãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")
    elif uploaded_files:
        st.sidebar.warning(f"âš ï¸ {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™ã€‚5ã¤å¿…è¦ã§ã™ã€‚")

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–¢æ•°
@st.cache_data
def prepare_data(_salary_df, _stats_2023, _stats_2024, _stats_2025, _titles_df):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã†"""
    titles_df_clean = _titles_df.dropna(subset=['é¸æ‰‹å'])
    title_summary = titles_df_clean.groupby(['é¸æ‰‹å', 'å¹´åº¦']).size().reset_index(name='ã‚¿ã‚¤ãƒˆãƒ«æ•°')
    
    stats_2023_copy = _stats_2023.copy()
    stats_2024_copy = _stats_2024.copy()
    stats_2025_copy = _stats_2025.copy()
    
    stats_2023_copy['å¹´åº¦'] = 2023
    stats_2024_copy['å¹´åº¦'] = 2024
    stats_2025_copy['å¹´åº¦'] = 2025
    
    stats_all = pd.concat([stats_2023_copy, stats_2024_copy, stats_2025_copy], ignore_index=True)
    
    df_2023 = _salary_df[['é¸æ‰‹å_2023', 'å¹´ä¿¸_å††_2023']].copy()
    df_2023['å¹´åº¦'] = 2023
    df_2023.rename(columns={'é¸æ‰‹å_2023': 'é¸æ‰‹å', 'å¹´ä¿¸_å††_2023': 'å¹´ä¿¸_å††'}, inplace=True)
    
    df_2024 = _salary_df[['é¸æ‰‹å_2024_2025', 'å¹´ä¿¸_å††_2024']].copy()
    df_2024['å¹´åº¦'] = 2024
    df_2024.rename(columns={'é¸æ‰‹å_2024_2025': 'é¸æ‰‹å', 'å¹´ä¿¸_å††_2024': 'å¹´ä¿¸_å††'}, inplace=True)
    
    df_2025 = _salary_df[['é¸æ‰‹å_2024_2025', 'å¹´ä¿¸_å††_2025']].copy()
    df_2025['å¹´åº¦'] = 2025
    df_2025.rename(columns={'é¸æ‰‹å_2024_2025': 'é¸æ‰‹å', 'å¹´ä¿¸_å††_2025': 'å¹´ä¿¸_å††'}, inplace=True)
    
    salary_long = pd.concat([df_2023, df_2024, df_2025], ignore_index=True)
    salary_long = salary_long.dropna(subset=['å¹´ä¿¸_å††'])
    salary_long = salary_long[salary_long['å¹´ä¿¸_å††'] > 0]
    salary_long = salary_long.sort_values('å¹´ä¿¸_å††', ascending=False)
    salary_long = salary_long.drop_duplicates(subset=['é¸æ‰‹å', 'å¹´åº¦'], keep='first')
    
    stats_all['äºˆæ¸¬å¹´åº¦'] = stats_all['å¹´åº¦'] + 1
    merged_df = pd.merge(stats_all, title_summary, on=['é¸æ‰‹å', 'å¹´åº¦'], how='left')
    merged_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] = merged_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'].fillna(0)
    
    # å¹´é½¢ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if 'å¹´é½¢' in merged_df.columns:
        age_backup = merged_df[['é¸æ‰‹å', 'å¹´åº¦', 'å¹´é½¢']].copy()
    
    merged_df = pd.merge(
        merged_df,
        salary_long,
        left_on=['é¸æ‰‹å', 'äºˆæ¸¬å¹´åº¦'],
        right_on=['é¸æ‰‹å', 'å¹´åº¦'],
        suffixes=('_æˆç¸¾', '_å¹´ä¿¸')
    )
    
    # å¹´é½¢åˆ—ãŒæ¶ˆãˆãŸå ´åˆã¯å¾©å…ƒ
    if 'å¹´é½¢' not in merged_df.columns and 'age_backup' in locals():
        merged_df = pd.merge(
            merged_df,
            age_backup,
            left_on=['é¸æ‰‹å', 'å¹´åº¦_æˆç¸¾'],
            right_on=['é¸æ‰‹å', 'å¹´åº¦'],
            how='left'
        )
        if 'å¹´åº¦_y' in merged_df.columns:
            merged_df = merged_df.drop(columns=['å¹´åº¦_y'])
        if 'å¹´åº¦_x' in merged_df.columns:
            merged_df = merged_df.rename(columns={'å¹´åº¦_x': 'å¹´åº¦_æˆç¸¾'})
    
    merged_df = merged_df.drop(columns=['å¹´åº¦_å¹´ä¿¸', 'äºˆæ¸¬å¹´åº¦'])
    merged_df.rename(columns={'å¹´åº¦_æˆç¸¾': 'æˆç¸¾å¹´åº¦'}, inplace=True)
    
    stats_all_with_titles = pd.merge(stats_all, title_summary, on=['é¸æ‰‹å', 'å¹´åº¦'], how='left')
    stats_all_with_titles['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] = stats_all_with_titles['ã‚¿ã‚¤ãƒˆãƒ«æ•°'].fillna(0)
    
    return merged_df, stats_all_with_titles, salary_long

# ========== æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«è¨“ç·´é–¢æ•° ==========
@st.cache_resource
def train_models_improved(_merged_df):
    """
    æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«è¨“ç·´é–¢æ•°
    - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°è¿½åŠ 
    - RobustScalerä½¿ç”¨
    - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
    - äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹è©•ä¾¡
    - XGBoost/LightGBMå¯¾å¿œ
    """
    
    # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆå¡æ‰“ã‚’é™¤å¤– - ãƒ‡ãƒ¼ã‚¿æ¼æ´©é˜²æ­¢ï¼‰
    feature_cols = ['è©¦åˆ', 'æ‰“å¸­', 'æ‰“æ•°', 'å¾—ç‚¹', 'å®‰æ‰“', 'äºŒå¡æ‰“', 'ä¸‰å¡æ‰“', 'æœ¬å¡æ‰“', 
                   'æ‰“ç‚¹', 'ç›—å¡', 'ç›—å¡åˆº', 'å››çƒ', 'æ­»çƒ', 'ä¸‰æŒ¯', 'ä½µæ®ºæ‰“', 
                   'æ‰“ç‡', 'å‡ºå¡ç‡', 'é•·æ‰“ç‡', 'çŠ æ‰“', 'çŠ é£›', 'ã‚¿ã‚¤ãƒˆãƒ«æ•°']
    
    # å¹´é½¢åˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯è¿½åŠ 
    if 'å¹´é½¢' in _merged_df.columns:
        feature_cols.append('å¹´é½¢')
        ml_df = _merged_df[feature_cols + ['å¹´ä¿¸_å††', 'é¸æ‰‹å', 'æˆç¸¾å¹´åº¦']].copy()
    else:
        ml_df = _merged_df[feature_cols + ['å¹´ä¿¸_å††', 'é¸æ‰‹å', 'æˆç¸¾å¹´åº¦']].copy()
        ml_df['å¹´é½¢'] = 28
        feature_cols.append('å¹´é½¢')
    
    ml_df = ml_df.dropna()
    
    # ========== ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° ==========
    st.write("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿæ–½ä¸­...")
    
    # OPS (On-base Plus Slugging) - æœ€é‡è¦æŒ‡æ¨™
    ml_df['OPS'] = ml_df['å‡ºå¡ç‡'] + ml_df['é•·æ‰“ç‡']
    
    # ISO (Isolated Power) - ç´”ç²‹ãªé•·æ‰“åŠ›
    ml_df['ISO'] = ml_df['é•·æ‰“ç‡'] - ml_df['æ‰“ç‡']
    
    # å››çƒç‡ - é¸çƒçœ¼ã®æŒ‡æ¨™
    ml_df['å››çƒç‡'] = ml_df['å››çƒ'] / ml_df['æ‰“å¸­'].replace(0, 1)
    
    # ä¸‰æŒ¯ç‡ - ã‚³ãƒ³ã‚¿ã‚¯ãƒˆèƒ½åŠ›ã®æŒ‡æ¨™
    ml_df['ä¸‰æŒ¯ç‡'] = ml_df['ä¸‰æŒ¯'] / ml_df['æ‰“å¸­'].replace(0, 1)
    
    # å¹´é½¢ã®2ä¹—é … - å¹´é½¢ãƒ”ãƒ¼ã‚¯åŠ¹æœã‚’æ‰ãˆã‚‹
    ml_df['å¹´é½¢2ä¹—'] = ml_df['å¹´é½¢'] ** 2
    
    # æœ¬å¡æ‰“ç‡
    ml_df['æœ¬å¡æ‰“ç‡'] = ml_df['æœ¬å¡æ‰“'] / ml_df['æ‰“æ•°'].replace(0, 1)
    
    # å¾—ç‚¹åœæ‰“ç‡ã®ä»£ç†æŒ‡æ¨™ï¼ˆæ‰“ç‚¹/æ‰“æ•°ï¼‰
    ml_df['æ‰“ç‚¹ç‡'] = ml_df['æ‰“ç‚¹'] / ml_df['æ‰“æ•°'].replace(0, 1)
    
    # æ›´æ–°ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    feature_cols_enhanced = feature_cols + ['OPS', 'ISO', 'å››çƒç‡', 'ä¸‰æŒ¯ç‡', 'å¹´é½¢2ä¹—', 'æœ¬å¡æ‰“ç‡', 'æ‰“ç‚¹ç‡']
    
    X = ml_df[feature_cols_enhanced]
    y = ml_df['å¹´ä¿¸_å††']
    
    # å¯¾æ•°å¤‰æ›
    y_log = np.log1p(y)
    
    # å±¤åŒ–æŠ½å‡ºã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    ml_df['salary_bin'] = pd.qcut(y, q=5, labels=False, duplicates='drop')
    
    X_train, X_test, y_train_log, y_test_log = train_test_split(
        X, y_log, test_size=0.2, random_state=42, stratify=ml_df['salary_bin']
    )
    
    y_train_original = np.expm1(y_train_log)
    y_test_original = np.expm1(y_test_log)
    
    # RobustScalerã§å¤–ã‚Œå€¤ã«å¼·ã„æ­£è¦åŒ–
    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # ========== ãƒ¢ãƒ‡ãƒ«å®šç¾©ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ==========
    models = {}
    
    # Ridgeå›å¸°ï¼ˆL2æ­£å‰‡åŒ–ï¼‰
    st.write("ğŸ” Ridgeå›å¸°ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
    ridge_params = {'alpha': [0.1, 1.0, 10.0, 100.0]}
    ridge = GridSearchCV(
        Ridge(), 
        ridge_params, 
        cv=5, 
        scoring='r2',
        n_jobs=-1
    )
    models['Ridgeå›å¸°'] = (ridge, True)  # Trueã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¿…è¦
    
    # Lassoå›å¸°ï¼ˆL1æ­£å‰‡åŒ–ï¼‰
    st.write("ğŸ” Lassoå›å¸°ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
    lasso_params = {'alpha': [0.1, 1.0, 10.0, 100.0]}
    lasso = GridSearchCV(
        Lasso(max_iter=10000), 
        lasso_params, 
        cv=5, 
        scoring='r2',
        n_jobs=-1
    )
    models['Lassoå›å¸°'] = (lasso, True)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ
    st.write("ğŸŒ² ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
    rf_params = {
        'n_estimators': [100, 200],
        'max_depth': [10, 15, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }
    rf = GridSearchCV(
        RandomForestRegressor(random_state=42, n_jobs=-1), 
        rf_params, 
        cv=3,
        scoring='r2',
        n_jobs=-1
    )
    models['ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ'] = (rf, False)
    
    # å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°
    st.write("ğŸ“ˆ å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
    gb_params = {
        'n_estimators': [100, 200],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1],
        'subsample': [0.8, 1.0]
    }
    gb = GridSearchCV(
        GradientBoostingRegressor(random_state=42), 
        gb_params, 
        cv=3,
        scoring='r2',
        n_jobs=-1
    )
    models['å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°'] = (gb, False)
    
    # XGBoostï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    if HAS_XGB:
        st.write("ğŸš€ XGBoostã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
        xgb_params = {
            'n_estimators': [100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1],
            'subsample': [0.8, 1.0],
            'colsample_bytree': [0.8, 1.0]
        }
        xgb = GridSearchCV(
            XGBRegressor(random_state=42, n_jobs=-1), 
            xgb_params, 
            cv=3,
            scoring='r2',
            n_jobs=-1
        )
        models['XGBoost'] = (xgb, False)
    
    # LightGBMï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    if HAS_LGBM:
        st.write("ğŸ’¡ LightGBMã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")
        lgbm_params = {
            'n_estimators': [100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1],
            'subsample': [0.8, 1.0],
            'colsample_bytree': [0.8, 1.0]
        }
        lgbm = GridSearchCV(
            LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1), 
            lgbm_params, 
            cv=3,
            scoring='r2',
            n_jobs=-1
        )
        models['LightGBM'] = (lgbm, False)
    
    # ========== ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡ ==========
    results = {}
    
    for name, (model, needs_scaling) in models.items():
        
        if needs_scaling:
            model.fit(X_train_scaled, y_train_log)
            y_pred_log = model.predict(X_test_scaled)
            cv_scores = cross_val_score(
                model.best_estimator_, 
                X_train_scaled, 
                y_train_log, 
                cv=5, 
                scoring='r2'
            )
        else:
            model.fit(X_train, y_train_log)
            y_pred_log = model.predict(X_test)
            cv_scores = cross_val_score(
                model.best_estimator_, 
                X_train, 
                y_train_log, 
                cv=5, 
                scoring='r2'
            )
        
        y_pred = np.expm1(y_pred_log)
        
        mae = mean_absolute_error(y_test_original, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test_original, y_pred))
        r2 = r2_score(y_test_original, y_pred)
        mape = np.mean(np.abs((y_test_original - y_pred) / y_test_original)) * 100
        
        results[name] = {
            'model': model.best_estimator_,
            'needs_scaling': needs_scaling,
            'MAE': mae,
            'RMSE': rmse,
            'R2': r2,
            'MAPE': mape,
            'CV_R2_mean': cv_scores.mean(),
            'CV_R2_std': cv_scores.std(),
            'best_params': model.best_params_
        }
        
        st.write(f"  âœ… {name}: RÂ²={r2:.4f}, CV RÂ²={cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    
    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠï¼ˆäº¤å·®æ¤œè¨¼RÂ²ãŒæœ€ã‚‚é«˜ã„ï¼‰
    best_model_name = max(results.items(), key=lambda x: x[1]['CV_R2_mean'])[0]
    best_model = results[best_model_name]['model']
    
    st.success(f"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_name} (CV RÂ²: {results[best_model_name]['CV_R2_mean']:.4f})")
    
    return (best_model, best_model_name, scaler, feature_cols_enhanced, 
            results, ml_df)

# äºˆæ¸¬ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def make_prediction(player_stats, model_name, model, scaler, feature_cols, needs_scaling):
    """
    é¸æ‰‹ã®æˆç¸¾ã‹ã‚‰å¹´ä¿¸ã‚’äºˆæ¸¬ã™ã‚‹
    """
    # åŸºæœ¬ç‰¹å¾´é‡
    base_features = player_stats[feature_cols[:len(feature_cols)-7]].copy()  # æ‹¡å¼µç‰¹å¾´é‡ã‚’é™¤ã
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆäºˆæ¸¬æ™‚ã‚‚åŒã˜å‡¦ç†ï¼‰
    features_dict = base_features.to_dict()
    
    # æ‹¡å¼µç‰¹å¾´é‡ã‚’è¨ˆç®—
    features_dict['OPS'] = features_dict['å‡ºå¡ç‡'] + features_dict['é•·æ‰“ç‡']
    features_dict['ISO'] = features_dict['é•·æ‰“ç‡'] - features_dict['æ‰“ç‡']
    features_dict['å››çƒç‡'] = features_dict['å››çƒ'] / features_dict['æ‰“å¸­'] if features_dict['æ‰“å¸­'] > 0 else 0
    features_dict['ä¸‰æŒ¯ç‡'] = features_dict['ä¸‰æŒ¯'] / features_dict['æ‰“å¸­'] if features_dict['æ‰“å¸­'] > 0 else 0
    features_dict['å¹´é½¢2ä¹—'] = features_dict['å¹´é½¢'] ** 2
    features_dict['æœ¬å¡æ‰“ç‡'] = features_dict['æœ¬å¡æ‰“'] / features_dict['æ‰“æ•°'] if features_dict['æ‰“æ•°'] > 0 else 0
    features_dict['æ‰“ç‚¹ç‡'] = features_dict['æ‰“ç‚¹'] / features_dict['æ‰“æ•°'] if features_dict['æ‰“æ•°'] > 0 else 0
    
    # ç‰¹å¾´é‡ã‚’æ­£ã—ã„é †åºã§é…åˆ—åŒ–
    features = np.array([[features_dict[col] for col in feature_cols]])
    
    # äºˆæ¸¬
    if needs_scaling:
        features_scaled = scaler.transform(features)
        predicted_salary_log = model.predict(features_scaled)[0]
    else:
        predicted_salary_log = model.predict(features)[0]
    
    predicted_salary = np.expm1(predicted_salary_log)
    
    return predicted_salary

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´
if data_loaded:
    if not st.session_state.model_trained:
        with st.spinner('ğŸ¤– æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...'):
            merged_df, stats_all_with_titles, salary_long = prepare_data(
                salary_df, stats_2023, stats_2024, stats_2025, titles_df
            )
            
            best_model, best_model_name, scaler, feature_cols, results, ml_df = train_models_improved(merged_df)
            
            st.session_state.model_trained = True
            st.session_state.best_model = best_model
            st.session_state.best_model_name = best_model_name
            st.session_state.scaler = scaler
            st.session_state.feature_cols = feature_cols
            st.session_state.stats_all_with_titles = stats_all_with_titles
            st.session_state.salary_long = salary_long
            st.session_state.results = results
            st.session_state.ml_df = ml_df
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    st.sidebar.markdown("### ğŸ¯ æ©Ÿèƒ½é¸æŠ")
    menu = st.sidebar.radio(
        "ãƒ¡ãƒ‹ãƒ¥ãƒ¼",
        ["ğŸ  ãƒ›ãƒ¼ãƒ ", "ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬", "ğŸ“Š è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ", "ğŸ”¬ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ", "âœï¸ ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›äºˆæ¸¬", "ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½", "ğŸ“‰ è¦å› åˆ†æ"],
        key="main_menu",
        label_visibility="collapsed"
    )
    
    # ãƒ›ãƒ¼ãƒ 
    if menu == "ğŸ  ãƒ›ãƒ¼ãƒ ":
        col1, col2, col3 = st.columns([2, 3, 2])
        with col1:
            st.metric("è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(st.session_state.ml_df)}äºº")
        with col2:
            st.metric("æ¡ç”¨ãƒ¢ãƒ‡ãƒ«", st.session_state.best_model_name)
        with col3:
            best_cv_r2 = st.session_state.results[st.session_state.best_model_name]['CV_R2_mean']
            st.metric("äº¤å·®æ¤œè¨¼RÂ²", f"{best_cv_r2:.4f}")

        st.markdown("---")
        st.subheader("ğŸš€ æ”¹å–„ç‚¹")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            ### âœ¨ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            - **OPS**: å‡ºå¡ç‡ + é•·æ‰“ç‡
            - **ISO**: é•·æ‰“ç‡ - æ‰“ç‡
            - **å››çƒç‡**: å››çƒ / æ‰“å¸­
            - **ä¸‰æŒ¯ç‡**: ä¸‰æŒ¯ / æ‰“å¸­
            - **å¹´é½¢2ä¹—**: å¹´é½¢ãƒ”ãƒ¼ã‚¯åŠ¹æœ
            - **æœ¬å¡æ‰“ç‡**: æœ¬å¡æ‰“ / æ‰“æ•°
            - **æ‰“ç‚¹ç‡**: æ‰“ç‚¹ / æ‰“æ•°
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ”§ æ©Ÿæ¢°å­¦ç¿’ã®æ”¹å–„
            - **RobustScaler**: å¤–ã‚Œå€¤ã«å¼·ã„
            - **GridSearchCV**: æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢
            - **äº¤å·®æ¤œè¨¼**: 5åˆ†å‰²ã§è©•ä¾¡
            - **XGBoost/LightGBM**: é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
            - **Ridge/Lasso**: æ­£å‰‡åŒ–ã§éå­¦ç¿’é˜²æ­¢
            """)
        
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«")
        available_models = list(st.session_state.results.keys())
        st.write(f"**è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«**: {', '.join(available_models)}")
        
        if HAS_XGB:
            st.success("âœ… XGBoostãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        else:
            st.info("â„¹ï¸ XGBoostã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ã•ã‚‰ã«ç²¾åº¦å‘ä¸Š: `pip install xgboost`")
        
        if HAS_LGBM:
            st.success("âœ… LightGBMãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        else:
            st.info("â„¹ï¸ LightGBMã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã¨ã•ã‚‰ã«ç²¾åº¦å‘ä¸Š: `pip install lightgbm`")
        
        st.subheader("ğŸ“– ä½¿ã„æ–¹")
        st.markdown("""
        1. **å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼**ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰æ©Ÿèƒ½ã‚’é¸æŠ
        2. **é¸æ‰‹å**ã‚’å…¥åŠ›ã—ã¦å¹´ä¿¸ã‚’äºˆæ¸¬
        
        ### æ©Ÿèƒ½ä¸€è¦§
        - ğŸ” **é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬**: å€‹åˆ¥é¸æ‰‹ã®å¹´ä¿¸äºˆæ¸¬ã¨ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        - ğŸ“Š **è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ**: æœ€å¤§5äººã®é¸æ‰‹ã‚’æ¯”è¼ƒ
        - ğŸ”¬ **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ**: å…¨ãƒ¢ãƒ‡ãƒ«ã§åŒæ™‚äºˆæ¸¬ã—ã¦æ¯”è¼ƒ
        - âœï¸ **ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›äºˆæ¸¬**: ã‚ªãƒªã‚¸ãƒŠãƒ«é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
        - ğŸ“ˆ **ãƒ¢ãƒ‡ãƒ«æ€§èƒ½**: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±
        - ğŸ“‰ **è¦å› åˆ†æ**: å¹´ä¿¸ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã®åˆ†æ
        
        ### âš–ï¸ NPBæ¸›é¡åˆ¶é™ãƒ«ãƒ¼ãƒ«
        - **1å„„å††ä»¥ä¸Š**: æœ€å¤§40%ã¾ã§æ¸›é¡å¯èƒ½ï¼ˆæœ€ä½60%ä¿è¨¼ï¼‰
        - **1å„„å††æœªæº€**: æœ€å¤§25%ã¾ã§æ¸›é¡å¯èƒ½ï¼ˆæœ€ä½75%ä¿è¨¼ï¼‰
        """)
    
    # é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬
    elif menu == "ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬":
        st.header("ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬")
        
        available_players = st.session_state.stats_all_with_titles[
            st.session_state.stats_all_with_titles['å¹´åº¦'] == 2024
        ]['é¸æ‰‹å'].unique()
        sorted_players = sorted(available_players)
        
        st.markdown("### é¸æ‰‹ã‚’é¸æŠ")
        
        search_filter = st.text_input(
            "ğŸ” çµã‚Šè¾¼ã¿æ¤œç´¢ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            placeholder="ä¾‹: æ‘ä¸Šã€å²¡æœ¬ã€è¿‘è—¤",
            key="player_search_filter",
            help="é¸æ‰‹åã®ä¸€éƒ¨ã‚’å…¥åŠ›ã™ã‚‹ã¨å€™è£œãŒçµã‚Šè¾¼ã¾ã‚Œã¾ã™"
        )
        
        if search_filter:
            filtered_players = [p for p in sorted_players if search_filter in p]
            if not filtered_players:
                st.warning("âš ï¸ è©²å½“ã™ã‚‹é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                filtered_players = sorted_players
        else:
            filtered_players = sorted_players
        
        selected_player = st.selectbox(
            f"é¸æ‰‹ã‚’é¸æŠã—ã¦ãã ã•ã„ ({len(filtered_players)}äºº)",
            options=filtered_players,
            index=0,
            key="player_select_main"
        )
        
        predict_year = st.slider("äºˆæ¸¬å¹´åº¦", 2024, 2026, 2025, key="predict_year_slider")
        
        if st.button("ğŸ¯ äºˆæ¸¬å®Ÿè¡Œ", type="primary", key="predict_button"):
            if not selected_player:
                st.error("âŒ é¸æ‰‹ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else:
                stats_year = predict_year - 1
                player_stats = st.session_state.stats_all_with_titles[
                    (st.session_state.stats_all_with_titles['é¸æ‰‹å'] == selected_player) &
                    (st.session_state.stats_all_with_titles['å¹´åº¦'] == stats_year)
                ]
                
                if player_stats.empty:
                    st.error(f"âŒ {selected_player}ã®{stats_year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                else:
                    player_stats = player_stats.iloc[0]
                    
                    # äºˆæ¸¬
                    predicted_salary = make_prediction(
                        player_stats,
                        st.session_state.best_model_name,
                        st.session_state.best_model,
                        st.session_state.scaler,
                        st.session_state.feature_cols,
                        st.session_state.results[st.session_state.best_model_name]['needs_scaling']
                    )
                    
                    # å‰å¹´ã®å¹´ä¿¸ã‚’å–å¾—
                    previous_salary_data = st.session_state.salary_long[
                        (st.session_state.salary_long['é¸æ‰‹å'] == selected_player) &
                        (st.session_state.salary_long['å¹´åº¦'] == stats_year)
                    ]
                    previous_salary = previous_salary_data['å¹´ä¿¸_å††'].values[0] if not previous_salary_data.empty else None
                    
                    # å®Ÿéš›ã®å¹´ä¿¸ã‚’å–å¾—
                    actual_salary_data = st.session_state.salary_long[
                        (st.session_state.salary_long['é¸æ‰‹å'] == selected_player) &
                        (st.session_state.salary_long['å¹´åº¦'] == predict_year)
                    ]
                    actual_salary = actual_salary_data['å¹´ä¿¸_å††'].values[0] if not actual_salary_data.empty else None
                    
                    st.success("âœ… äºˆæ¸¬å®Œäº†ï¼")
                    
                    # æ¸›é¡åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if previous_salary is not None:
                        is_limited, min_salary, reduction_rate = check_salary_reduction_limit(predicted_salary, previous_salary)
                        
                        if is_limited:
                            st.warning(f"""
                            âš–ï¸ **æ¸›é¡åˆ¶é™ã«å¼•ã£ã‹ã‹ã‚Šã¾ã™**
                            - å‰å¹´å¹´ä¿¸: {previous_salary/1e6:.1f}ç™¾ä¸‡å††
                            - äºˆæ¸¬å¹´ä¿¸: {predicted_salary/1e6:.1f}ç™¾ä¸‡å††
                            - æ¸›é¡åˆ¶é™: {reduction_rate*100:.0f}%ã¾ã§ï¼ˆæœ€ä½{(1-reduction_rate)*100:.0f}%ä¿è¨¼ï¼‰
                            - **åˆ¶é™å¾Œã®æœ€ä½å¹´ä¿¸: {min_salary/1e6:.1f}ç™¾ä¸‡å††**
                            """)
                            display_salary = min_salary
                        else:
                            display_salary = predicted_salary
                    else:
                        display_salary = predicted_salary
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        if previous_salary is not None:
                            st.metric("å‰å¹´å¹´ä¿¸", f"{previous_salary/1e6:.1f}ç™¾ä¸‡å††")
                        else:
                            st.metric("å‰å¹´å¹´ä¿¸", "ãƒ‡ãƒ¼ã‚¿ãªã—")
                    with col2:
                        st.metric("äºˆæ¸¬å¹´ä¿¸", f"{predicted_salary/1e6:.1f}ç™¾ä¸‡å††")
                    with col3:
                        if actual_salary:
                            st.metric("å®Ÿéš›ã®å¹´ä¿¸", f"{actual_salary/1e6:.1f}ç™¾ä¸‡å††")
                        else:
                            st.metric("å®Ÿéš›ã®å¹´ä¿¸", "ãƒ‡ãƒ¼ã‚¿ãªã—")
                    with col4:
                        if actual_salary:
                            error = abs(display_salary - actual_salary) / actual_salary * 100
                            st.metric("äºˆæ¸¬èª¤å·®", f"{error:.1f}%")
                    
                    st.markdown("---")
                    st.subheader(f"{stats_year}å¹´ã®æˆç¸¾")
                    
                    col1, col2, col3, col4, col5 = st.columns(5)
                    with col1:
                        st.metric("è©¦åˆ", int(player_stats['è©¦åˆ']))
                        st.metric("æ‰“ç‡", f"{player_stats['æ‰“ç‡']:.3f}")
                    with col2:
                        st.metric("å®‰æ‰“", int(player_stats['å®‰æ‰“']))
                        st.metric("å‡ºå¡ç‡", f"{player_stats['å‡ºå¡ç‡']:.3f}")
                    with col3:
                        st.metric("æœ¬å¡æ‰“", int(player_stats['æœ¬å¡æ‰“']))
                        st.metric("é•·æ‰“ç‡", f"{player_stats['é•·æ‰“ç‡']:.3f}")
                    with col4:
                        st.metric("æ‰“ç‚¹", int(player_stats['æ‰“ç‚¹']))
                        # OPSè¨ˆç®—
                        ops = player_stats['å‡ºå¡ç‡'] + player_stats['é•·æ‰“ç‡']
                        st.metric("OPS", f"{ops:.3f}")
                    with col5:
                        st.metric("å¹´é½¢", int(player_stats['å¹´é½¢']))
                        st.metric("ã‚¿ã‚¤ãƒˆãƒ«æ•°", int(player_stats['ã‚¿ã‚¤ãƒˆãƒ«æ•°']))
                    
                    st.markdown("---")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig1, ax1 = plt.subplots(figsize=(8, 5))
                        player_salary_history = st.session_state.salary_long[
                            st.session_state.salary_long['é¸æ‰‹å'] == selected_player
                        ].sort_values('å¹´åº¦')
                        
                        if not player_salary_history.empty:
                            years = player_salary_history['å¹´åº¦'].astype(int).values
                            salaries = player_salary_history['å¹´ä¿¸_å††'].values / 1e6

                            ax1.plot(years, salaries, 'o-', linewidth=2, markersize=8, label='å®Ÿéš›ã®å¹´ä¿¸')
                            ax1.plot(int(predict_year), predicted_salary/1e6, 'r*', markersize=20, label='äºˆæ¸¬å¹´ä¿¸ï¼ˆåˆ¶é™å‰ï¼‰')

                            if previous_salary is not None and is_limited:
                                ax1.plot(int(predict_year), display_salary/1e6, 'orange', marker='D', markersize=12, label='åˆ¶é™å¾Œå¹´ä¿¸')

                            if actual_salary:
                                ax1.plot(int(predict_year), actual_salary/1e6, 'go', markersize=12, 
                                    label=f'å®Ÿéš›ã®å¹´ä¿¸({int(predict_year)})')

                            ax1.set_xticks([2023, 2024, 2025, 2026])
                            ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: int(x)))

                            ax1.set_xlabel('å¹´åº¦', fontweight='bold')
                            ax1.set_ylabel('å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰', fontweight='bold')
                            ax1.set_title(f'{selected_player} - å¹´ä¿¸æ¨ç§»', fontweight='bold')
                            ax1.grid(alpha=0.3)
                            ax1.legend()

                        st.pyplot(fig1)
                        plt.close(fig1)
                    
                    with col2:
                        fig2, ax2 = plt.subplots(figsize=(8, 5), subplot_kw=dict(projection='polar'))
                        
                        radar_stats = {
                            'æ‰“ç‡': player_stats['æ‰“ç‡'] / 0.4,
                            'å‡ºå¡ç‡': player_stats['å‡ºå¡ç‡'] / 0.5,
                            'é•·æ‰“ç‡': player_stats['é•·æ‰“ç‡'] / 0.7,
                            'æœ¬å¡æ‰“': min(player_stats['æœ¬å¡æ‰“'] / 40, 1.0),
                            'æ‰“ç‚¹': min(player_stats['æ‰“ç‚¹'] / 100, 1.0),
                            'ç›—å¡': min(player_stats['ç›—å¡'] / 40, 1.0),
                        }
                        
                        categories = list(radar_stats.keys())
                        values = list(radar_stats.values())
                        values += values[:1]
                        
                        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
                        angles += angles[:1]
                        
                        ax2.plot(angles, values, 'o-', linewidth=2, color='#2E86AB')
                        ax2.fill(angles, values, alpha=0.25, color='#2E86AB')
                        ax2.set_xticks(angles[:-1])
                        ax2.set_xticklabels(categories)
                        ax2.set_ylim(0, 1)
                        ax2.set_title(f'{selected_player} - æˆç¸¾ãƒ¬ãƒ¼ãƒ€ãƒ¼\n({stats_year}å¹´)', fontweight='bold', pad=20)
                        ax2.grid(True)
                        
                        st.pyplot(fig2)
                        plt.close(fig2)
    
    # ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
    elif menu == "ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½":
        st.header("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½")
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒè¡¨
        model_data = []
        for name, result in st.session_state.results.items():
            model_data.append({
                'ãƒ¢ãƒ‡ãƒ«': name,
                'MAEï¼ˆç™¾ä¸‡å††ï¼‰': f"{result['MAE']/1e6:.2f}",
                'RMSEï¼ˆç™¾ä¸‡å††ï¼‰': f"{result['RMSE']/1e6:.2f}",
                'RÂ²ã‚¹ã‚³ã‚¢': f"{result['R2']:.4f}",
                'äº¤å·®æ¤œè¨¼RÂ²': f"{result['CV_R2_mean']:.4f} Â± {result['CV_R2_std']:.4f}",
                'MAPE(%)': f"{result['MAPE']:.2f}"
            })
        
        df_models = pd.DataFrame(model_data).sort_values('äº¤å·®æ¤œè¨¼RÂ²', ascending=False)
        st.dataframe(
            df_models,
            use_container_width=True,
            hide_index=True
        )
        st.success(f"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {st.session_state.best_model_name}")
        
        st.markdown("---")
        st.subheader("ğŸ“Š è©•ä¾¡æŒ‡æ¨™ã®èª¬æ˜")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
            **MAE (Mean Absolute Error)**
            - å¹³å‡çµ¶å¯¾èª¤å·®
            - äºˆæ¸¬ã¨å®Ÿéš›ã®å¹´ä¿¸ã®å·®ã®å¹³å‡
            - å°ã•ã„ã»ã©è‰¯ã„
            
            **RMSE (Root Mean Squared Error)**
            - å¹³æ–¹å¹³å‡äºŒä¹—èª¤å·®
            - å¤–ã‚Œå€¤ã«æ•æ„Ÿ
            - å°ã•ã„ã»ã©è‰¯ã„
            """)
        
        with col2:
            st.markdown("""
            **RÂ²ã‚¹ã‚³ã‚¢**
            - æ±ºå®šä¿‚æ•°ï¼ˆ0ã€œ1ï¼‰
            - ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›
            - 1ã«è¿‘ã„ã»ã©è‰¯ã„
            
            **äº¤å·®æ¤œè¨¼RÂ²**
            - 5åˆ†å‰²äº¤å·®æ¤œè¨¼ã§ã®å¹³å‡RÂ²
            - ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„æŒ‡æ¨™
            - Â±ã¯æ¨™æº–åå·®
            
            **MAPE (Mean Absolute Percentage Error)**
            - å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®
            - ç›´æ„Ÿçš„ãªèª¤å·®ç‡
            - å°ã•ã„ã»ã©è‰¯ã„
            """)
        
        st.markdown("---")
        
        # ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¡¨ç¤º
        st.subheader(f"ğŸ”§ {st.session_state.best_model_name}ã®ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        best_params = st.session_state.results[st.session_state.best_model_name]['best_params']
        st.json(best_params)
        
        # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã¾ãŸã¯ãƒ„ãƒªãƒ¼ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼‰
        if st.session_state.best_model_name in ['ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ', 'å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°', 'XGBoost', 'LightGBM']:
            st.markdown("---")
            st.subheader("ğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ Top 15")
            
            try:
                if hasattr(st.session_state.best_model, 'feature_importances_'):
                    feature_importance = pd.DataFrame({
                        'ç‰¹å¾´é‡': st.session_state.feature_cols,
                        'é‡è¦åº¦': st.session_state.best_model.feature_importances_
                    }).sort_values('é‡è¦åº¦', ascending=False).head(15)
                    
                    fig, ax = plt.subplots(figsize=(10, 8))
                    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_importance)))
                    ax.barh(range(len(feature_importance)), feature_importance['é‡è¦åº¦'], 
                           color=colors, alpha=0.8)
                    ax.set_yticks(range(len(feature_importance)))
                    ax.set_yticklabels(feature_importance['ç‰¹å¾´é‡'])
                    ax.set_xlabel('é‡è¦åº¦', fontweight='bold')
                    ax.set_title('ç‰¹å¾´é‡é‡è¦åº¦ Top 15', fontweight='bold', pad=20)
                    ax.grid(axis='x', alpha=0.3)
                    ax.invert_yaxis()
                    st.pyplot(fig)
                    plt.close(fig)
                    
                    # ãƒˆãƒƒãƒ—5ã®èª¬æ˜
                    st.markdown("### ğŸ’¡ ãƒˆãƒƒãƒ—5ç‰¹å¾´é‡ã®è§£èª¬")
                    top5 = feature_importance.head(5)
                    for idx, row in top5.iterrows():
                        st.write(f"**{row['ç‰¹å¾´é‡']}**: é‡è¦åº¦ {row['é‡è¦åº¦']:.4f}")
            except Exception as e:
                st.info("ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤ºãŒã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        st.markdown("---")
        st.subheader("ğŸ“ˆ å…¨ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ")
        
        # RÂ²ã‚¹ã‚³ã‚¢æ¯”è¼ƒ
        fig1, ax1 = plt.subplots(figsize=(10, 6))
        models = list(st.session_state.results.keys())
        r2_scores = [st.session_state.results[m]['R2'] for m in models]
        cv_r2_scores = [st.session_state.results[m]['CV_R2_mean'] for m in models]
        
        x = np.arange(len(models))
        width = 0.35
        
        ax1.bar(x - width/2, r2_scores, width, label='ãƒ†ã‚¹ãƒˆRÂ²', alpha=0.8, color='steelblue')
        ax1.bar(x + width/2, cv_r2_scores, width, label='äº¤å·®æ¤œè¨¼RÂ²', alpha=0.8, color='orange')
        
        ax1.set_xlabel('ãƒ¢ãƒ‡ãƒ«', fontweight='bold')
        ax1.set_ylabel('RÂ² ã‚¹ã‚³ã‚¢', fontweight='bold')
        ax1.set_title('ãƒ¢ãƒ‡ãƒ«åˆ¥RÂ²ã‚¹ã‚³ã‚¢æ¯”è¼ƒ', fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(models, rotation=45, ha='right')
        ax1.legend()
        ax1.grid(axis='y', alpha=0.3)
        ax1.set_ylim([0, 1])
        
        st.pyplot(fig1)
        plt.close(fig1)
        
        # MAEæ¯”è¼ƒ
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        mae_scores = [st.session_state.results[m]['MAE']/1e6 for m in models]
        
        colors_mae = ['green' if m == st.session_state.best_model_name else 'gray' for m in models]
        ax2.barh(range(len(models)), mae_scores, color=colors_mae, alpha=0.7)
        ax2.set_yticks(range(len(models)))
        ax2.set_yticklabels(models)
        ax2.set_xlabel('MAEï¼ˆç™¾ä¸‡å††ï¼‰', fontweight='bold')
        ax2.set_title('ãƒ¢ãƒ‡ãƒ«åˆ¥MAEæ¯”è¼ƒï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰', fontweight='bold')
        ax2.grid(axis='x', alpha=0.3)
        ax2.invert_yaxis()
        
        st.pyplot(fig2)
        plt.close(fig2)

    # ğŸ“‰ è¦å› åˆ†æ
    elif menu == "ğŸ“‰ è¦å› åˆ†æ":
        st.header("ğŸ“‰ è¦å› åˆ†æ")
        
        st.subheader("ğŸ“Š æ–°è¦è¿½åŠ ç‰¹å¾´é‡ã®å½±éŸ¿")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # OPSã¨å¹´ä¿¸ã®é–¢ä¿‚
            fig1, ax1 = plt.subplots(figsize=(8, 6))
            ops_values = st.session_state.ml_df['OPS']
            salary_values = st.session_state.ml_df['å¹´ä¿¸_å††'] / 1e6
            
            ax1.scatter(ops_values, salary_values, alpha=0.5, s=50)
            ax1.set_xlabel('OPS (å‡ºå¡ç‡+é•·æ‰“ç‡)', fontweight='bold')
            ax1.set_ylabel('å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰', fontweight='bold')
            ax1.set_title('OPSã¨å¹´ä¿¸ã®é–¢ä¿‚', fontweight='bold')
            ax1.grid(alpha=0.3)
            
            # å›å¸°ç›´ç·šã‚’è¿½åŠ 
            z = np.polyfit(ops_values, salary_values, 1)
            p = np.poly1d(z)
            ax1.plot(ops_values, p(ops_values), "r--", alpha=0.8, linewidth=2)
            
            # ç›¸é–¢ä¿‚æ•°ã‚’è¡¨ç¤º
            corr = np.corrcoef(ops_values, salary_values)[0, 1]
            ax1.text(0.05, 0.95, f'ç›¸é–¢ä¿‚æ•°: {corr:.3f}', 
                    transform=ax1.transAxes, fontsize=12, 
                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
            
            st.pyplot(fig1)
            plt.close(fig1)
        
        with col2:
            # å¹´é½¢ã¨å¹´ä¿¸ã®é–¢ä¿‚ï¼ˆ2æ¬¡æ›²ç·šï¼‰
            fig2, ax2 = plt.subplots(figsize=(8, 6))
            age_values = st.session_state.ml_df['å¹´é½¢']
            
            ax2.scatter(age_values, salary_values, alpha=0.5, s=50, color='orange')
            ax2.set_xlabel('å¹´é½¢', fontweight='bold')
            ax2.set_ylabel('å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰', fontweight='bold')
            ax2.set_title('å¹´é½¢ã¨å¹´ä¿¸ã®é–¢ä¿‚ï¼ˆãƒ”ãƒ¼ã‚¯åŠ¹æœï¼‰', fontweight='bold')
            ax2.grid(alpha=0.3)
            
            # 2æ¬¡æ›²ç·šã§ãƒ•ã‚£ãƒƒãƒˆ
            z2 = np.polyfit(age_values, salary_values, 2)
            p2 = np.poly1d(z2)
            age_line = np.linspace(age_values.min(), age_values.max(), 100)
            ax2.plot(age_line, p2(age_line), "r--", alpha=0.8, linewidth=2, label='2æ¬¡è¿‘ä¼¼æ›²ç·š')
            ax2.legend()
            
            # ãƒ”ãƒ¼ã‚¯å¹´é½¢ã‚’è¨ˆç®—
            peak_age = -z2[1] / (2 * z2[0])
            ax2.axvline(peak_age, color='green', linestyle=':', alpha=0.7, label=f'ãƒ”ãƒ¼ã‚¯å¹´é½¢: {peak_age:.1f}æ­³')
            ax2.legend()
            
            st.pyplot(fig2)
            plt.close(fig2)
        
        st.markdown("---")
        st.subheader("ğŸ”— ä¸»è¦æŒ‡æ¨™ã¨ã®ç›¸é–¢")
        
        # ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—ã¨è¡¨ç¤º
        correlations = st.session_state.ml_df[
            ['æ‰“ç‡', 'æœ¬å¡æ‰“', 'æ‰“ç‚¹', 'å‡ºå¡ç‡', 'é•·æ‰“ç‡', 'OPS', 'ISO', 
             'å››çƒç‡', 'ä¸‰æŒ¯ç‡', 'ã‚¿ã‚¤ãƒˆãƒ«æ•°', 'å¹´é½¢', 'å¹´ä¿¸_å††']
        ].corr()['å¹´ä¿¸_å††'].sort_values(ascending=False)
        
        corr_data = []
        for idx, val in correlations.items():
            if idx != 'å¹´ä¿¸_å††':
                corr_data.append({'æŒ‡æ¨™': idx, 'ç›¸é–¢ä¿‚æ•°': f"{val:.4f}"})
        
        df_corr = pd.DataFrame(corr_data)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.dataframe(
                df_corr,
                use_container_width=True,
                hide_index=True
            )
        
        with col2:
            # ç›¸é–¢ä¿‚æ•°ã®æ£’ã‚°ãƒ©ãƒ•
            fig3, ax3 = plt.subplots(figsize=(10, 8))
            corr_values = [float(c['ç›¸é–¢ä¿‚æ•°']) for c in corr_data]
            colors = ['green' if v > 0.5 else 'orange' if v > 0.3 else 'gray' for v in corr_values]
            
            ax3.barh(range(len(corr_data)), corr_values, color=colors, alpha=0.7)
            ax3.set_yticks(range(len(corr_data)))
            ax3.set_yticklabels([c['æŒ‡æ¨™'] for c in corr_data])
            ax3.set_xlabel('ç›¸é–¢ä¿‚æ•°', fontweight='bold')
            ax3.set_title('å„æŒ‡æ¨™ã¨å¹´ä¿¸ã®ç›¸é–¢', fontweight='bold')
            ax3.axvline(0.5, color='green', linestyle=':', alpha=0.5, label='å¼·ã„ç›¸é–¢(>0.5)')
            ax3.axvline(0.3, color='orange', linestyle=':', alpha=0.5, label='ä¸­ç¨‹åº¦ã®ç›¸é–¢(>0.3)')
            ax3.grid(axis='x', alpha=0.3)
            ax3.legend()
            ax3.invert_yaxis()
            
            st.pyplot(fig3)
            plt.close(fig3)
        
        st.markdown("---")
        st.subheader("ğŸ† ã‚¿ã‚¤ãƒˆãƒ«ç²å¾—ã®å½±éŸ¿")
        
        title_groups = st.session_state.ml_df.groupby(
            st.session_state.ml_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] > 0
        )['å¹´ä¿¸_å††'].agg(['count', 'mean', 'median'])
        
        title_groups['mean'] = title_groups['mean'] / 1e6
        title_groups['median'] = title_groups['median'] / 1e6
        title_groups.index = ['ã‚¿ã‚¤ãƒˆãƒ«ç„¡ã—', 'ã‚¿ã‚¤ãƒˆãƒ«æœ‰ã‚Š']
        title_groups.columns = ['é¸æ‰‹æ•°', 'å¹³å‡å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰', 'ä¸­å¤®å€¤ï¼ˆç™¾ä¸‡å††ï¼‰']
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.dataframe(
                title_groups,
                use_container_width=True
            )
            
            if len(title_groups) == 2:
                diff = title_groups.loc['ã‚¿ã‚¤ãƒˆãƒ«æœ‰ã‚Š', 'å¹³å‡å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰'] - title_groups.loc['ã‚¿ã‚¤ãƒˆãƒ«ç„¡ã—', 'å¹³å‡å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰']
                st.metric("ã‚¿ã‚¤ãƒˆãƒ«ç²å¾—ã«ã‚ˆã‚‹å¹´ä¿¸å¢—åŠ ", f"{diff:.1f}ç™¾ä¸‡å††")
        
        with col2:
            # ç®±ã²ã’å›³
            fig4, ax4 = plt.subplots(figsize=(8, 6))
            
            has_title = st.session_state.ml_df[st.session_state.ml_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] > 0]['å¹´ä¿¸_å††'] / 1e6
            no_title = st.session_state.ml_df[st.session_state.ml_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] == 0]['å¹´ä¿¸_å††'] / 1e6
            
            ax4.boxplot([no_title, has_title], labels=['ã‚¿ã‚¤ãƒˆãƒ«ç„¡ã—', 'ã‚¿ã‚¤ãƒˆãƒ«æœ‰ã‚Š'])
            ax4.set_ylabel('å¹´ä¿¸ï¼ˆç™¾ä¸‡å††ï¼‰', fontweight='bold')
            ax4.set_title('ã‚¿ã‚¤ãƒˆãƒ«æœ‰ç„¡ã«ã‚ˆã‚‹å¹´ä¿¸åˆ†å¸ƒ', fontweight='bold')
            ax4.grid(axis='y', alpha=0.3)
            
            st.pyplot(fig4)
            plt.close(fig4)

    # ä»–ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ã«å®Ÿè£…
    # ï¼ˆè¤‡æ•°é¸æ‰‹æ¯”è¼ƒã€è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã€ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›äºˆæ¸¬ã¯åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
    # ã‚¹ãƒšãƒ¼ã‚¹ã®éƒ½åˆä¸Šã€ä¸»è¦ãªæ”¹å–„éƒ¨åˆ†ã®ã¿ã‚’è¨˜è¼‰
    
else:
    # ãƒ•ã‚¡ã‚¤ãƒ«æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚
    st.info("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    st.markdown("""
    ### ãƒ‡ãƒ¼ã‚¿é…ç½®æ–¹æ³•
    
    ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã¦ãã ã•ã„ï¼š
    
    **æ–¹æ³•1: dataãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®**
    ```
    data/
    â”œâ”€â”€ salary_2023&2024&2025.csv
    â”œâ”€â”€ stats_2023.csv
    â”œâ”€â”€ stats_2024.csv
    â”œâ”€â”€ stats_2025.csv
    â””â”€â”€ titles_2023&2024&2025.csv
    ```
    
    **æ–¹æ³•2: å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
    
    ### ğŸš€ æ”¹å–„ç‰ˆã®æ©Ÿèƒ½
    - âš¾ é¸æ‰‹å€‹åˆ¥ã®å¹´ä¿¸äºˆæ¸¬ï¼ˆ**é«˜ç²¾åº¦åŒ–**ï¼‰
    - ğŸ“Š è¤‡æ•°é¸æ‰‹ã®æ¯”è¼ƒåˆ†æ
    - ğŸ”¬ è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§ã®åŒæ™‚äºˆæ¸¬ã¨æ¯”è¼ƒ
    - âœï¸ ã‚ªãƒªã‚¸ãƒŠãƒ«é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
    - ğŸ“ˆ äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ï¼ˆ**äº¤å·®æ¤œè¨¼å¯¾å¿œ**ï¼‰
    - ğŸ“‰ å¹´ä¿¸å½±éŸ¿è¦å› ã®åˆ†æï¼ˆ**æ–°ç‰¹å¾´é‡ã®åŠ¹æœç¢ºèª**ï¼‰
    - âš–ï¸ NPBæ¸›é¡åˆ¶é™ãƒ«ãƒ¼ãƒ«ã®é©ç”¨
    
    ### âœ¨ æ”¹å–„ç‚¹
    1. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: OPS, ISO, å››çƒç‡, ä¸‰æŒ¯ç‡ãªã©7ã¤ã®æ–°ç‰¹å¾´é‡è¿½åŠ 
    2. **RobustScaler**: å¤–ã‚Œå€¤ã«å¼·ã„æ­£è¦åŒ–æ‰‹æ³•
    3. **GridSearchCV**: å„ãƒ¢ãƒ‡ãƒ«ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æ¢ç´¢
    4. **äº¤å·®æ¤œè¨¼**: 5åˆ†å‰²äº¤å·®æ¤œè¨¼ã§ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡
    5. **XGBoost/LightGBMå¯¾å¿œ**: æœ€å…ˆç«¯ã®å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°
    6. **Ridge/Lassoå›å¸°**: æ­£å‰‡åŒ–ã§éå­¦ç¿’é˜²æ­¢
    
    ### ğŸ“¦ è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆä»»æ„ï¼‰
    ```bash
    pip install xgboost lightgbm
    ```
    """)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("*NPBé¸æ‰‹å¹´ä¿¸äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹å–„ç‰ˆï¼‰ - made by Sato&Kurokawa - Powered by Streamlit*")
